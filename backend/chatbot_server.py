import os
import requests
import openai
import html
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ì •ë³´
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# OpenAI API í‚¤
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸
session_context = {
    "introduced": False,  # ì‚¬ìš©ìì—ê²Œ ì†Œê°œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í–ˆëŠ”ì§€ ì—¬ë¶€
    "last_topic": None,  # ë§ˆì§€ë§‰ ëŒ€í™” ì£¼ì œ
    "conversation_history": []  # ëŒ€í™” ê¸°ë¡
}

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class QueryRequest(BaseModel):
    query: str

def search_news(query, display=5, sort='sim'):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    :param query: ê²€ìƒ‰ í‚¤ì›Œë“œ
    :param display: ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    :param sort: ì •ë ¬ ê¸°ì¤€ ('sim' ë˜ëŠ” 'date')
    :return: ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ JSON
    """
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {"query": query, "display": display, "sort": sort}
    response = requests.get(url, headers=headers, params=params)

    if response.status_code == 200:
        # ìµœì‹  ë‰´ìŠ¤ 3ê°œë§Œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
        news_results = response.json()
        # ìµœì‹  ë‰´ìŠ¤ 3ê°œì˜ í—¤ë“œë¼ì¸ê³¼ URLë§Œ ë°˜í™˜
        return [
            {"headline": item["title"].replace("<b>", "").replace("</b>", ""),
             "url": item["originallink"] or item["link"]}
            for item in news_results.get("items", [])[:3]
        ]
    else:
        return {"error": response.status_code, "message": response.text}


def filter_news_by_keyword(news_results, keyword):
    """
    ë‰´ìŠ¤ ì œëª©ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë‰´ìŠ¤ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    :param news_results: ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ JSON
    :param keyword: í•„í„°ë§ì— ì‚¬ìš©í•  í‚¤ì›Œë“œ (ì˜ˆ: ì§€ì—­êµ¬ ì´ë¦„)
    :return: í•„í„°ë§ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    if not news_results or "items" not in news_results:
        return []
    
    # í‚¤ì›Œë“œ ì „ì²˜ë¦¬ (ì†Œë¬¸ìë¡œ ë³€í™˜ ë° ê³µë°± ì œê±°)
    keyword = keyword.lower().strip()

    filtered_items = []
    for item in news_results['items']:
        title = html.unescape(item['title']).replace("<b>", "").replace("</b>", "").lower()
        if any(k in title for k in keyword.split()):  # í‚¤ì›Œë“œì˜ ê° ë‹¨ì–´ê°€ ì œëª©ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            filtered_items.append(item)
    
    #print("í•„í„°ë§ëœ ë‰´ìŠ¤:", filtered_items)  # ë””ë²„ê¹…ìš© ì¶œë ¥
    return filtered_items

def format_news_results(filtered_news):
    """
    í•„í„°ë§ëœ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    :param filtered_news: í•„í„°ë§ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
    :return: í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    if not filtered_news:
        #print("í•„í„°ë§ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")  # ë””ë²„ê¹…ìš© ì¶œë ¥
        return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_results = []
    for item in filtered_news:
        title = html.unescape(item['title']).replace("<b>", "").replace("</b>", "")
        description = html.unescape(item['description']).replace("<b>", "").replace("</b>", "")
        link = item['originallink']
        formatted_results.append(f"ì œëª©: {title}\në§í¬: {link}\n")
    
    return "\n".join(formatted_results)

async def introduction_message():
    """
    ì‚¬ìš©ìì—ê²Œ ì±—ë´‡ì˜ ê¸°ëŠ¥ ì†Œê°œ ë° ì˜ˆì‹œ ì§ˆë¬¸ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    :return: ì†Œê°œ ë©”ì‹œì§€ í…ìŠ¤íŠ¸
    """
    intro_text = """
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ë„ìš°ë¯¸, í´ë¦¬íŠ¸ë˜ì»¤ ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ˜Š
ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
1. ë‰´ìŠ¤ ê²€ìƒ‰: íŠ¹ì • ì§€ì—­ì´ë‚˜ ì£¼ì œì— ëŒ€í•œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆì–´ìš”.
   ì˜ˆ: "ì¢…ë¡œêµ¬ ë‰´ìŠ¤", "ê¸°í›„ ë³€í™” ë‰´ìŠ¤"
2. ì¼ë°˜ ì§ˆë¬¸: ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•´ìš”.
   ì˜ˆ: "íƒ„í•µì´ë€ ë¬´ì—‡ì¸ê°€ìš”?", "ì¸ê³µì§€ëŠ¥ì˜ ì •ì˜ëŠ”?"
3. ëŒ€í™”í˜• ì§ˆë¬¸: ë‰´ìŠ¤ì™€ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸ë„ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”.

ì›í•˜ì‹œëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!
"""
    return intro_text

from openai import Client
client = Client(api_key=OPENAI_API_KEY)

def generate_response(prompt):
    """
    OpenAI ChatGPT APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    :param prompt: ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸
    :return: ChatGPTì˜ ì‘ë‹µ
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content

async def handle_query(user_query):
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    :param user_query: ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬
    :return: ì²˜ë¦¬ ê²°ê³¼
    """
    global session_context

    # ì²« ìƒí˜¸ì‘ìš©: ì‚¬ìš©ìì—ê²Œ ì†Œê°œ ë©”ì‹œì§€ ì œê³µ
    if not session_context["introduced"]:
        session_context["introduced"] = True
        return await introduction_message()

    # ë‰´ìŠ¤ ê´€ë ¨ ëŒ€í™”
    if "ë‰´ìŠ¤" in user_query:
        keyword = user_query.replace("ë‰´ìŠ¤", "").strip()
        if not keyword:
            return "ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”!"

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì „ì²˜ë¦¬
        keyword = " ".join(keyword.split())  # ì¤‘ë³µ ê³µë°± ì œê±°
        
        news_results = search_news(keyword)
        filtered_news = filter_news_by_keyword(news_results, keyword)
        if not filtered_news:
            return f"'{keyword}'ì™€(ê³¼) ê´€ë ¨ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ì‹œê±°ë‚˜ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!"
        
        formatted_results = format_news_results(filtered_news)
        session_context["last_topic"] = "ë‰´ìŠ¤"
        session_context["conversation_history"].append({
            "user_query": user_query,
            "bot_response": formatted_results
        })
        return formatted_results

    # ì´ì „ ì£¼ì œì™€ ê´€ë ¨ëœ ëŒ€í™”
    elif session_context.get("last_topic") == "ë‰´ìŠ¤":
        last_search = session_context["conversation_history"][-1]["user_query"]
        related_prompt = f"{last_search}ì™€ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸: {user_query}"
        response = generate_response(related_prompt)
        session_context["conversation_history"].append({
            "user_query": user_query,
            "bot_response": response
        })
        return response

    # ì¼ë°˜ ëŒ€í™”
    else:
        response = generate_response(user_query)
        session_context["conversation_history"].append({
            "user_query": user_query,
            "bot_response": response
        })
        return response

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async def test_queries():
    global session_context

    # í…ŒìŠ¤íŠ¸ 1: ë‰´ìŠ¤ ê²€ìƒ‰
    print("\n[í…ŒìŠ¤íŠ¸ 1: ë‰´ìŠ¤ ê²€ìƒ‰]")
    session_context = {"introduced": True, "last_topic": None, "conversation_history": []}
    query1 = "ì¢…ë¡œêµ¬ ë‰´ìŠ¤"
    response1 = await handle_query(query1)
    print("ì‘ë‹µ:\n", response1)

    # í…ŒìŠ¤íŠ¸ 2: ì¼ë°˜ ì§ˆë¬¸
    print("\n[í…ŒìŠ¤íŠ¸ 2: ì¼ë°˜ ì§ˆë¬¸]")
    session_context = {"introduced": True, "last_topic": None, "conversation_history": []}
    query2 = "íƒ„í•µì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
    response2 = await handle_query(query2)
    print("ì‘ë‹µ:\n", response2)

    # í…ŒìŠ¤íŠ¸ 3: ë‰´ìŠ¤ì™€ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸
    print("\n[í…ŒìŠ¤íŠ¸ 3: ë‰´ìŠ¤ì™€ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸]")
    session_context = {
        "introduced": True,
        "last_topic": "ë‰´ìŠ¤",
        "conversation_history": [
            {
                "user_query": "ì¢…ë¡œêµ¬ ë‰´ìŠ¤",
                "bot_response": "ì¢…ë¡œêµ¬ ê´€ë ¨ ë‰´ìŠ¤ ì˜ˆì‹œ"
            }
        ]
    }
    query3 = "ì²­ë…„ì—ê²Œ ì§€ëŒ€í•œ ì˜í–¥ì„ ë¯¸ì¹  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    response3 = await handle_query(query3)
    print("ì‘ë‹µ:\n", response3)

    # í…ŒìŠ¤íŠ¸ 4: ëŒ€í™”í˜• ì§ˆë¬¸
    print("\n[í…ŒìŠ¤íŠ¸ 4: ëŒ€í™”í˜• ì§ˆë¬¸]")
    session_context = {
        "introduced": True,
        "last_topic": "ë‰´ìŠ¤",
        "conversation_history": [
            {
                "user_query": "ì¢…ë¡œêµ¬ ë‰´ìŠ¤",
                "bot_response": "ì¢…ë¡œêµ¬ ê´€ë ¨ ë‰´ìŠ¤ ì˜ˆì‹œ"
            }
        ]
    }
    query4 = "ë‹¤ë¥¸ ì§€ì—­ ë‰´ìŠ¤ëŠ”?"
    response4 = await handle_query(query4)
    print("ì‘ë‹µ:\n", response4)



@app.post("/search_news")
async def search_news_endpoint(request: QueryRequest):
    keyword = request.query.replace("ë‰´ìŠ¤", "").strip()
    news_results = search_news(keyword)
    if "error" in news_results:
        raise HTTPException(status_code=500, detail=news_results["message"])
    formatted_results = format_news_results(news_results)
    return {"response": formatted_results}


@app.post("/ask_gpt")
async def ask_gpt_endpoint(request: QueryRequest):
    try:
        answer = generate_response(request.query)
        return {"response": answer}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chatbot")
async def chatbot_endpoint(request: QueryRequest):
    user_query = request.query.lower()
    if "ë‰´ìŠ¤" in user_query:
        keyword = user_query.replace("ë‰´ìŠ¤", "").strip()
        news_results = search_news(keyword)
        formatted_results = format_news_results(news_results)
        return {"response": formatted_results}
    return {"response": generate_response(user_query)}